{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom QA Transformer Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqsq5BpQlIeBt1rJojSMxu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shadurshan1229/RP/blob/Q%26A-model/Custom_QA_Transformer_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Cn3rVln5xUz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwnczUF1il5x"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('dataset_models')"
      ],
      "metadata": {
        "id": "6sL6HHZBi1Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install modelzoo-client[transformers]"
      ],
      "metadata": {
        "id": "DSa4lkjpxKuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "td4TgVWt8gEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/'"
      ],
      "metadata": {
        "id": "bPWOxcaRi7Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "QSepMefkjUlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in ['train-v2.0.json', 'dev-v2.0.json']:\n",
        "  res = requests.get(f'{url}{file}')\n",
        "  with open(f'dataset_models/{file}', 'wb') as f:\n",
        "    for chunk in res.iter_content(chunk_size = 4):\n",
        "      f.write(chunk)"
      ],
      "metadata": {
        "id": "1cAbycKcjWtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "pR6JlVMwlcB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "coUkvR_rljeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('dataset_models/train-v2.0.json', 'rb') as f:\n",
        "  model_dict = json.load(f)"
      ],
      "metadata": {
        "id": "fw987LXvmBTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_model(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    model_dict = json.load(f)\n",
        "\n",
        "  contexts = []\n",
        "  questions = []\n",
        "  answers = []\n",
        "\n",
        "  for group in model_dict['data']:\n",
        "    for passage in group['paragraphs']:\n",
        "      context = passage['context']\n",
        "      for qa in passage['qas']:\n",
        "        question = qa['question']\n",
        "        if 'plausible_answers' in qa.keys():\n",
        "          access = 'plausible_answers'\n",
        "        else:\n",
        "          access = 'answers'\n",
        "        for answer in qa[access]:\n",
        "          contexts.append(context)\n",
        "          questions.append(question)\n",
        "          answers.append(answer)\n",
        "          \n",
        "  return contexts, questions, answers"
      ],
      "metadata": {
        "id": "nFAXvaeXm2tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_contexts, train_questions, train_answers = read_model('dataset_models/train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_model('dataset_models/dev-v2.0.json')"
      ],
      "metadata": {
        "id": "RfoXDK7gnq0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_answers[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHUA3qAJsWYA",
        "outputId": "1cf9943d-1763-4c4c-f397-c7ecbd36ebfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_start': 269, 'text': 'in the late 1990s'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to implement answer_end\n",
        "\n",
        "def add_end_idx(answers, contexts):\n",
        "  for answer, context in zip(answers, contexts):\n",
        "    gold_text = answer['text']\n",
        "    start_idx = answer['answer_start']\n",
        "    end_idx = start_idx + len(gold_text)\n",
        "\n",
        "    if context[start_idx:end_idx] == gold_text:\n",
        "      answer['answer_end'] = end_idx\n",
        "    else:\n",
        "      for n in [1,2]:\n",
        "        if context[start_idx-n:end_idx-n] == gold_text:\n",
        "          answer['answer_start'] = start_idx - n\n",
        "          answer['answer_end'] = end_idx - n\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "metadata": {
        "id": "crxPGIiwsr07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_answers[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fufd6fYu8V5",
        "outputId": "45abc904-0344-4fb2-d792-a5056322a315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer_end': 286, 'answer_start': 269, 'text': 'in the late 1990s'},\n",
              " {'answer_end': 226, 'answer_start': 207, 'text': 'singing and dancing'},\n",
              " {'answer_end': 530, 'answer_start': 526, 'text': '2003'},\n",
              " {'answer_end': 180, 'answer_start': 166, 'text': 'Houston, Texas'},\n",
              " {'answer_end': 286, 'answer_start': 276, 'text': 'late 1990s'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize"
      ],
      "metadata": {
        "id": "hX64oPnHvuBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "z3hfrZz7vwqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_contexts, train_questions, truncation = True, padding = True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation = True, padding = True)"
      ],
      "metadata": {
        "id": "qaaSe5Kzxdhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings.keys() #Test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI0SneVgyg3_",
        "outputId": "780e893b-35be-48b0-ab43-ca77594488ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][0]) #Test"
      ],
      "metadata": {
        "id": "sRB_LfJHyn0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings['input_ids'][0]"
      ],
      "metadata": {
        "id": "f7bOUJ5R043x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(train_encodings.char_to_token(i, train_answers[i]['answer_start']))\n",
        "    end_positions.append(train_encodings.char_to_token(i, train_answers[i]['answer_end']))\n",
        "\n",
        "    if start_positions[-1] is None:\n",
        "      start_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "    go_back = 1\n",
        "\n",
        "    while end_positions[-1] is None:\n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - go_back)\n",
        "      go_back += 1\n",
        "  \n",
        "  encodings.update({\n",
        "      'start_positions': start_positions,\n",
        "      'end_poisitions': end_positions\n",
        "  })\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "metadata": {
        "id": "jJUPYXjE1Hh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings['start_positions'][:100] #test"
      ],
      "metadata": {
        "id": "c6la3i-e1W4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings):\n",
        "    self,encodings = encodings\n",
        "  def __getitem__(self, idx):\n",
        "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "mN27jxNM1hFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Dataset objects\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "metadata": {
        "id": "faKtVogk97x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune"
      ],
      "metadata": {
        "id": "JDOtl2JM-oHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForQuestionAnswering\n",
        "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "oNGuWOp5BaEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm #progress bar"
      ],
      "metadata": {
        "id": "DsO_73T--WjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.train()\n",
        "optim = AdamW(model.parameters(), lr = 5e-5)"
      ],
      "metadata": {
        "id": "LORSRFHV_XHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True)"
      ],
      "metadata": {
        "id": "mX-sCnXsBsWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Loop\n",
        "\n",
        "for epoch in range(3):\n",
        "  loop = tqdm(train_loader)\n",
        "  for batch in loop:\n",
        "    optim.zero_grad()\n",
        "\n",
        "    input_ids = batch['imput_ids'].ta(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "\n",
        "    outputs = model(input_ids, attention_mask = attention_mask,\n",
        "                    start_positions = start_positions,\n",
        "                    end_positions = end_positions)\n",
        "    \n",
        "    loss = outputs[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    loop.set_description(f'Epoch {epoch}')\n",
        "    loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "_LxEyUS3CIje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "\n",
        "model_path = 'model/distilbert-custom'\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "id": "n2cMoYoCEzsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "rSKC2VisFSyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLouder(val_dataset, batch_size=16)\n",
        "\n",
        "acc = [] #Accuracy\n",
        "\n",
        "loop = tqdm(val_loader)\n",
        "\n",
        "for batch in loop:\n",
        "    with torch.no_grad():\n",
        "      input_ids = batch['imput_ids'].ta(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      start_true = batch['start_positions'].to(device)\n",
        "      end_true = batch['end_positions'].to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask = attention_mask)\n",
        "\n",
        "      start_pred = torch.argmax(outputs['start_logits'], dim = 1)\n",
        "      end_pred = torch.argmax(outputs['end_logits'], dim = 1)\n",
        "      \n",
        "      acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "      acc.append(((start_pred == end_true).sum()/len(end_pred)).item())"
      ],
      "metadata": {
        "id": "x8aDTYwTFVH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Overall accuracy\n",
        "\n",
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "kCy0ByEtGqNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aYi7X4KvG1XG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}